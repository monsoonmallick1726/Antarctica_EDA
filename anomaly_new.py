# -*- coding: utf-8 -*-
"""Anomaly_new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1thJAC3jC9BRdsP9eKxN9EGmQ-stI1xTR
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
file_path = '/content/Marble Point_day.csv'
df = pd.read_csv(file_path, encoding='ISO-8859-1')
print("First 5 rows:")
display(df.head())
print("Dataset Info:")
df.info()
print("Descriptive Statistics:")
display(df.describe(include='all'))
print("ðŸ”¹ Missing Values per Column:")
display(df.isnull().sum())

df['Date'] = pd.to_datetime(df[['Year', 'Month', 'Day']])

df.set_index('Date', inplace=True)

columns_to_drop = [col for col in df.columns if 'wt_' in col or df[col].isnull().sum() == len(df)]
df.drop(columns=columns_to_drop, inplace=True)

print("Dropped columns:", columns_to_drop)

df.interpolate(method='time', inplace=True)

df_cleaned=df.dropna()

print("Remaining Missing Values:")
print(df_cleaned.isnull().sum())

print("Cleaned Data Preview:")
display(df_cleaned.head())

print(df_cleaned.columns.tolist())

import matplotlib.pyplot as plt
import seaborn as sns

sns.set(style="whitegrid")

# 1. Plot time series of key features
plt.figure(figsize=(16, 5))
df['Temperature(Â¡Ã¦)'].plot(label='Temperature', color='tomato')
plt.title("Temperature Over Time")
plt.ylabel("Temperature (Â°C)")
plt.xlabel("Date")
plt.legend()
plt.show()

# 2. Pressure
plt.figure(figsize=(16, 5))
df['Pressure(hPa)'].plot(label='Pressure', color='steelblue')
plt.title("Pressure Over Time")
plt.ylabel("Pressure (hPa)")
plt.xlabel("Date")
plt.legend()
plt.show()

# 3. Wind Speed
plt.figure(figsize=(16, 5))
df['Wind Speed(m/s)'].plot(label='Wind Speed', color='seagreen')
plt.title("Wind Speed Over Time")
plt.ylabel("Wind Speed (m/s)")
plt.xlabel("Date")
plt.legend()
plt.show()

# 4. Pairplot to check feature correlations
selected_cols = ['Temperature(Â¡Ã¦)', 'Pressure(hPa)', 'Wind Speed(m/s)', 'Wind Direction']
sns.pairplot(df_cleaned[selected_cols].dropna())
plt.suptitle("Pairwise Feature Relationships", y=1.02)
plt.show()

# 5. Correlation Heatmap
plt.figure(figsize=(8, 6))
corr = df_cleaned[selected_cols].corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Heatmap")
plt.show()

from sklearn.neighbors import NearestNeighbors
import numpy as np
from sklearn.preprocessing import StandardScaler

X = df_cleaned[['Temperature(Â¡Ã¦)', 'Pressure(hPa)', 'Wind Speed(m/s)']]
X_scaled = StandardScaler().fit_transform(X)
# Use the same scaled data
neighbors = NearestNeighbors(n_neighbors=10)
neighbors_fit = neighbors.fit(X_scaled)
distances, indices = neighbors_fit.kneighbors(X_scaled)

# Sort the distances for the 10th nearest neighbor
distances = np.sort(distances[:, 9])
plt.figure(figsize=(10, 5))
plt.plot(distances)
plt.title("K-Distance Graph to Tune eps")
plt.xlabel("Points sorted by distance")
plt.ylabel("10th Nearest Neighbor Distance")
plt.grid(True)
plt.show()

from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler

# 1. Select relevant features for clustering (temperature, pressure, wind speed)
X = df_cleaned[['Temperature(Â¡Ã¦)', 'Pressure(hPa)', 'Wind Speed(m/s)']]

# 2. Standardize the features
X_scaled = StandardScaler().fit_transform(X)

# 3. Apply DBSCAN
dbscan = DBSCAN(eps=0.5, min_samples=10)
df_cleaned['dbscan_cluster'] = dbscan.fit_predict(X_scaled)

# 4. Mark anomalies
df_cleaned['is_anomaly'] = df_cleaned['dbscan_cluster'] == -1

# 5. Visualize anomalies
plt.figure(figsize=(16, 6))
plt.plot(df_cleaned.index, df_cleaned['Temperature(Â¡Ã¦)'], label='Temperature', color='dodgerblue')
plt.scatter(df_cleaned[df_cleaned['is_anomaly']].index, df_cleaned[df_cleaned['is_anomaly']]['Temperature(Â¡Ã¦)'], color='red', label='DBSCAN Anomalies')
plt.title("Anomaly Detection Using DBSCAN")
plt.xlabel("Date")
plt.ylabel("Temperature (Â°C)")
plt.legend()
plt.show()

from sklearn.ensemble import IsolationForest

features = ['Temperature(Â¡Ã¦)', 'Pressure(hPa)', 'Wind Speed(m/s)']
X = df_cleaned[features].dropna()
contamination_values = [0.01, 0.025, 0.05, 0.075, 0.1]
for c in contamination_values:
    iso_forest = IsolationForest(contamination=c, random_state=42)
    preds = iso_forest.fit_predict(X_scaled)
    outliers = (preds == -1).sum()
    print(f"Contamination={c}: Anomalies detected = {outliers}")

from sklearn.ensemble import IsolationForest

features = ['Temperature(Â¡Ã¦)', 'Pressure(hPa)', 'Wind Speed(m/s)']
X = df_cleaned[features].dropna()

# 2. Standardize features
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. Apply Isolation Forest
iso_forest = IsolationForest(contamination=0.05, random_state=42)
df_cleaned['iso_anomaly'] = iso_forest.fit_predict(X_scaled)

# 4. Convert output: -1 = anomaly, 1 = normal
df_cleaned['iso_anomaly'] = df_cleaned['iso_anomaly'] == -1

# 5. Visualize anomalies on Temperature
plt.figure(figsize=(16, 6))
plt.plot(df_cleaned.index, df_cleaned['Temperature(Â¡Ã¦)'], label='Temperature', color='dodgerblue')
plt.scatter(df_cleaned[df_cleaned['iso_anomaly']].index, df_cleaned[df_cleaned['iso_anomaly']]['Temperature(Â¡Ã¦)'], color='red', label='Isolation Forest Anomalies')
plt.title("Anomaly Detection Using Isolation Forest")
plt.xlabel("Date")
plt.ylabel("Temperature (Â°C)")
plt.legend()
plt.show()

!pip install pmdarima

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

plt.figure(figsize=(14, 5))
plt.subplot(1, 2, 1)
plot_acf(df_cleaned['Temperature(Â¡Ã¦)'].dropna(), lags=40, ax=plt.gca())
plt.title("ACF (for q)")

plt.subplot(1, 2, 2)
plot_pacf(df_cleaned['Temperature(Â¡Ã¦)'].dropna(), lags=40, ax=plt.gca())
plt.title("PACF (for p)")
plt.tight_layout()
plt.show()

import pandas as pd
from statsmodels.tsa.arima.model import ARIMA
from sklearn.metrics import mean_squared_error
import numpy as np

# Make sure the datetime is the index (already done in earlier step)
df_arima = df[['Temperature(Â¡Ã¦)']].copy()
df_arima = df_arima.dropna()

# Fit ARIMA model (you can tune p, d, q based on AIC or autocorrelation plots)
model = ARIMA(df_arima['Temperature(Â¡Ã¦)'], order=(2, 1, 0))  # (p,d,q)
model_fit = model.fit()

# Forecast on the training data
forecast = model_fit.predict(start=1, end=len(df_arima)-1, typ='levels')

# Add to DataFrame
df_arima = df_arima.iloc[1:]  # shift due to differencing
df_arima['forecast'] = forecast

# Compute residuals and flag anomalies
df_arima['residual'] = df_arima['Temperature(Â¡Ã¦)'] - df_arima['forecast']
threshold = 2 * df_arima['residual'].std()
df_arima['arima_anomaly'] = df_arima['residual'].abs() > threshold

# Visualize
plt.figure(figsize=(16, 6))
plt.plot(df_arima.index, df_arima['Temperature(Â¡Ã¦)'], label='Actual', color='skyblue')
plt.plot(df_arima.index, df_arima['forecast'], label='Forecast', color='orange')
plt.scatter(df_arima[df_arima['arima_anomaly']].index,
            df_arima[df_arima['arima_anomaly']]['Temperature(Â¡Ã¦)'],
            color='red', label='ARIMA Anomalies')
plt.title("ARIMA-based Time Series Anomaly Detection")
plt.xlabel("Date")
plt.ylabel("Temperature (Â°C)")
plt.legend()
plt.show()

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler

# 1. Prepare temperature data (fill missing and normalize)
temp_series = df_cleaned[['Temperature(Â¡Ã¦)']].dropna()
scaler = MinMaxScaler()
temp_scaled = scaler.fit_transform(temp_series)

# 2. Create sequences for supervised learning
def create_sequences(data, time_steps=30):
    X, y = [], []
    for i in range(len(data) - time_steps):
        X.append(data[i:i + time_steps])
        y.append(data[i + time_steps])
    return np.array(X), np.array(y)

time_steps = 30
X, y = create_sequences(temp_scaled, time_steps)

# 3. Split into training and testing sets
split = int(len(X) * 0.8)
X_train, X_test = X[:split], X[split:]
y_train, y_test = y[:split], y[split:]

# 4. Define and train LSTM model
model = Sequential([
    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2])),
    Dense(1)
])

model.compile(optimizer='adam', loss='mse')
history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1, verbose=1)

# 5. Predict and compute error
y_pred = model.predict(X_test)
errors = np.abs(y_pred - y_test)

# 6. Threshold for anomaly
threshold = np.percentile(errors, 95)
anomalies = errors > threshold

# 7. Plot results
actual = scaler.inverse_transform(y_test)
predicted = scaler.inverse_transform(y_pred)

plt.figure(figsize=(16, 6))
plt.plot(actual, label='Actual Temp', color='skyblue')
plt.plot(predicted, label='Predicted Temp', color='orange')
plt.scatter(np.where(anomalies)[0], actual[anomalies], color='red', label='LSTM Anomalies')
plt.title("LSTM-Based Temperature Anomaly Detection")
plt.xlabel("Time Index")
plt.ylabel("Temperature (Â°C)")
plt.legend()
plt.show()

# Get DBSCAN anomaly indices
dbscan_anomalies = set(df_cleaned.index[df_cleaned['dbscan_cluster'] == -1])

# Get Isolation Forest anomaly indices
isoforest_anomalies = set(df_cleaned.index[df_cleaned['iso_anomaly']])

arima_anomalies = set(df_arima[df_arima['arima_anomaly'] == 1].index)

print("DBSCAN anomalies:", len(dbscan_anomalies))
print("Isolation Forest anomalies:", len(isoforest_anomalies))
print("ARIMA anomalies:", len(arima_anomalies))
print("Common anomalies:", len(dbscan_anomalies & isoforest_anomalies & arima_anomalies))

plt.figure(figsize=(16, 6))
plt.plot(df_cleaned['Year'], df_cleaned['Temperature(Â¡Ã¦)'], label='Temperature', color='gray')

# Highlight DBSCAN anomalies
plt.scatter(df_cleaned.loc[list(dbscan_anomalies), 'Year'],
            df_cleaned.loc[list(dbscan_anomalies), 'Temperature(Â¡Ã¦)'],
            color='blue', label='DBSCAN Anomalies', marker='x')

# Highlight Isolation Forest anomalies
plt.scatter(df_cleaned.loc[list(isoforest_anomalies), 'Year'],
            df_cleaned.loc[list(isoforest_anomalies), 'Temperature(Â¡Ã¦)'],
            color='red', label='Isolation Forest Anomalies', marker='o', facecolors='none')

plt.scatter(df_cleaned.loc[list(arima_anomalies), 'Year'],
            df_cleaned.loc[list(arima_anomalies), 'Temperature(Â¡Ã¦)'],
            color='orange', label='Arima Anomalies', marker='*', facecolors='none')

plt.title("Anomalies Detected by DBSCAN vs Isolation Forest vs Arima")
plt.xlabel("Year")
plt.ylabel("Temperature (Â°C)")
plt.legend()
plt.grid(True)
plt.show()

from matplotlib_venn import venn3
import matplotlib.pyplot as plt

# For Venn3 we can only use 3 sets at once. Let's compare Isolation Forest, DBSCAN, and LSTM
venn3([isoforest_anomalies, dbscan_anomalies, arima_anomalies],
      set_labels=('Isolation Forest', 'DBSCAN', 'ARIMA'))

plt.title("Anomaly Detection Overlap")
plt.show()

